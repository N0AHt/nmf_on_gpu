{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchnmf.nmf import NMF\n",
    "from torchnmf import metrics as mtx\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm \n",
    "import numpy as np\n",
    "import os\n",
    "import skimage.io as iio\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in some data to be factorized\n",
    "path = '/home/nrt2124/engram/cuttlefish/CUTTLEFISH_BEHAVIOR/cuttle_data_storage/2024_Interesting_skin_compiled_dataset/Nice skin manual crops/Lightroom Export_full res/'\n",
    "files = np.sort(os.listdir(path))\n",
    "images = iio.ImageCollection(path + '/*.tif')\n",
    "cuts = [1080, 720]\n",
    "cut_0 = cuts[0]\n",
    "cut_1 = cuts[1]\n",
    "\n",
    "shapes = np.empty((3, len(images)))\n",
    "for i, image in enumerate(tqdm(images)):\n",
    "   for j in range(3):\n",
    "      shapes[j,i] = image.shape[j]\n",
    "\n",
    "mask_0 = shapes[0,:] > cut_0\n",
    "mask_1 = shapes[1,:] > cut_1\n",
    "\n",
    "index_mask0 = np.where(mask_0 == True)[0]\n",
    "index_mask1 = np.where(mask_1 == True)[0]\n",
    "\n",
    "full_mask = np.intersect1d(index_mask0, index_mask1)\n",
    "\n",
    "#first filter out unusually small images\n",
    "print(len(images))\n",
    "images_cut = [images[i] for i in full_mask]\n",
    "print(len(images_cut))\n",
    "print(len(full_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_to_size(image, output_size):\n",
    "    height, width, c = image.shape\n",
    "\n",
    "\n",
    "    # Desired output size\n",
    "    new_height, new_width = output_size\n",
    "\n",
    "\n",
    "    # Calculate coordinates to crop at the center\n",
    "    start_x = (width // 2) - (new_width // 2)\n",
    "    start_y = (height // 2) - (new_height // 2)\n",
    "\n",
    "    # Crop the image\n",
    "    cropped_img = image[start_y:start_y+new_height, start_x:start_x+new_width]\n",
    "    return cropped_img\n",
    "\n",
    "\n",
    "\n",
    "cropped_ims  = []\n",
    "for image_cut in tqdm(images_cut):\n",
    "    cropped_ims.append(crop_image_to_size(image_cut, (cut_0, cut_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape and convert to grayscale\n",
    "cropped_ims_flipped = [np.max(cropped_im) - cropped_im for cropped_im in cropped_ims] #flip brighness values\n",
    "dataset = np.asarray(cropped_ims_flipped)\n",
    "\n",
    "# #grayscale data\n",
    "gray_data = 0.2989*dataset[:,:,:,0] + 0.5870*dataset[:,:,:,1]+0.1140*dataset[:,:,:,2]\n",
    "\n",
    "gray_data_flattened = gray_data.reshape(gray_data.shape[0], -1)\n",
    "print(gray_data_flattened.shape) #382 flattend images :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data for nmf\n",
    "V = torch.tensor(gray_data_flattened).to(torch.float32)\n",
    "print(V.shape)\n",
    "\n",
    "#create and train base model:\n",
    "rank = 300\n",
    "model = NMF(V.shape, rank=rank)\n",
    "\n",
    "#on gpu\n",
    "V = V.cuda()\n",
    "model = model.cuda()\n",
    "\n",
    "model.fit(V, tol = 0.0000001, max_iter = 3000)\n",
    "\n",
    "#return gpu resources\n",
    "model = model.cpu()\n",
    "V = V.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model:\n",
    "W_m = model.W.detach()\n",
    "H_m = model.H.detach()\n",
    "print('W shape: ', W_m.shape, ' H shape: ', H_m.shape)\n",
    "WH = W_m @ H_m.T\n",
    "print('WH shape: ', WH.shape)\n",
    "print('V shape: ', V.shape)\n",
    "\n",
    "euc = mtx.euclidean(WH, V.T)\n",
    "print(euc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise features\n",
    "\n",
    "# reshape to images\n",
    "features_images = np.empty((H_m.shape[0], gray_data.shape[1], gray_data.shape[2])) #number of features, image shape\n",
    "for i, factor in enumerate(W_m.T):\n",
    "    features_images[i] = factor.reshape(gray_data.shape[1], gray_data.shape[2])\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 7), subplot_kw={'xticks': (), 'yticks': ()})\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.imshow(features_images[i], cmap = 'viridis')\n",
    "    ax.set_title(f'Feature {i+1}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decompose a single image and see the reconstruction\n",
    "\n",
    "gray_image = gray_data[4]\n",
    "plt.imshow(gray_image, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "flat_image = gray_image.reshape(1,-1)\n",
    "flat_image = torch.tensor(flat_image)\n",
    "print(flat_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_new = flat_image.to(torch.float32)\n",
    "\n",
    "#model for inference on a single image - uses the same W matrix as the original model\n",
    "model_new = NMF(W=model.W.detach(), H=(V_new.shape[0], model.H.shape[1]), trainable_W=False)\n",
    "\n",
    "#to the GPU\n",
    "model_new.cuda()\n",
    "V_new = V_new.cuda()\n",
    "\n",
    "#inference\n",
    "model_new.fit(V_new, tol = 0.0000001, max_iter = 2000)\n",
    "\n",
    "#return the gpu\n",
    "V_new = V_new.cpu()\n",
    "model_new = model_new.cpu()\n",
    "\n",
    "image_H = model_new.H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_image = image_H @ W_m.T\n",
    "reshaped_image = reconstructed_image.reshape(gray_image.shape[0], gray_image.shape[1])\n",
    "\n",
    "fig, ax = plt.subplots(1,2, subplot_kw={'xticks': (), 'yticks': ()})\n",
    "ax[0].imshow(reshaped_image.detach().numpy(), cmap = 'gray')\n",
    "ax[0].set_title('Reconstructed Image')\n",
    "ax[1].imshow(gray_image, cmap = 'gray')\n",
    "ax[1].set_title('Original Image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = image_H\n",
    "indicies = list(range(len(components[0])))\n",
    "inx_components = list(zip(components[0], indicies))\n",
    "\n",
    "sorted_components = sorted(inx_components, key=lambda x: x[0])\n",
    "sorted_components.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 20\n",
    "idx = [sc[1] for sc in sorted_components[0:num_features]]\n",
    "\n",
    "features = model_new.W.t()\n",
    "image_components = features.reshape(features.shape[0], gray_image.shape[0], gray_image.shape[1])\n",
    "image_components = image_components.detach().cpu().numpy()\n",
    "\n",
    "top_features = image_components[idx]\n",
    "\n",
    "fig, axes = plt.subplots(4, 5, figsize=(15, 7), subplot_kw={'xticks': (), 'yticks': ()})\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.imshow(top_features[i], cmap = 'viridis')\n",
    "    ax.set_title(f'Feature {i+1}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparseness might be a good idea here... \n",
    "#and continuousness/contiguousness\n",
    "\n",
    "#might need to implement from scratch to make this work\n",
    "\n",
    "#invert image, so dark areas are bright!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO:\n",
    "\n",
    "# Try out sparse factorisation, maybe features are sparse?\n",
    "# Try to constrain this model further with a contiguousness metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for gpu stuff!\n",
    "from torchnmf.nmf import NMF\n",
    "V = torch.tensor(gray_data_flattened)\n",
    "\n",
    "\n",
    "model = NMF(V.t().shape, rank=100)\n",
    "print(model.W.size())\n",
    "print(model.H.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move to the gpu\n",
    "V = V.cuda()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(V.t(), tol = 0.000001, max_iter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()\n",
    "W = model.W.detach()\n",
    "H = model.H.detach()\n",
    "V = V.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WH = W @ H.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchnmf import metrics as mt\n",
    "euc = mt.euclidean(WH, V)\n",
    "print(euc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank15 = 47637596572.93673\n",
    "rank382 = 11927036790.584213\n",
    "rank382_lowtol_highmaxiter = 3550226976.273385\n",
    "rank15_lt_hm = 45533987442.6467\n",
    "rank383_lt_hm = 3446455585.170434\n",
    "rank100_lt_hm = 24825144844.55306\n",
    "\n",
    "print(rank15/rank382)\n",
    "print(rank382/rank382_lowtol_highmaxiter) #good improvement\n",
    "\n",
    "print(rank15/rank15_lt_hm) #not so impressive for low rank models...\n",
    "\n",
    "print(rank382_lowtol_highmaxiter/rank383_lt_hm) #slightly better...?\n",
    "\n",
    "print(rank382_lowtol_highmaxiter/ rank100_lt_hm) #way worse??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(H.shape)\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to images\n",
    "features_images = np.empty((H.t().shape[0], gray_data.shape[1], gray_data.shape[2])) #number of features, image shape\n",
    "for i, factor in enumerate(H.t()):\n",
    "    features_images[i] = factor.reshape(gray_data.shape[1], gray_data.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(15, 7), subplot_kw={'xticks': (), 'yticks': ()})\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.imshow(features_images[i+25], cmap = 'gray')\n",
    "    ax.set_title(f'Feature {i+1}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decompose a single image and see the reconstruction\n",
    "\n",
    "gray_image = gray_data[4]\n",
    "plt.imshow(gray_image, cmap = 'gray')\n",
    "plt.show()\n",
    "flat_image = gray_image.reshape(1,-1)\n",
    "flat_image = torch.tensor(flat_image)\n",
    "print(flat_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_image = flat_image.type(torch.float64)\n",
    "print(flat_image.dtype)\n",
    "print(model.W.dtype)\n",
    "print(flat_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = NMF(W, H=(flat_image.shape[0], model.H.t().shape[1]), trainable_W=False)\n",
    "model2.fit(flat_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = model.forward(flat_image.type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V = torch.randint(0,10,(50,50)).to(torch.float32)\n",
    "# V_new = torch.randint(0,10,(1,50)).to(torch.float32)\n",
    "\n",
    "V = torch.tensor(gray_data_flattened).to(torch.float32)\n",
    "V_new = flat_image.to(torch.float32)\n",
    "\n",
    "print(V.shape, V_new.shape)\n",
    "\n",
    "\n",
    "rank = 300\n",
    "model1 = NMF(V.shape, rank=rank)\n",
    "V = V.cuda()\n",
    "model1 = model1.cuda()\n",
    "model1.fit(V, tol = 0.0000001, max_iter = 2000)\n",
    "model1 = model1.cpu()\n",
    "V = V.cpu()\n",
    "\n",
    "\n",
    "model_new = NMF(W=model1.W.detach(), H=(V_new.shape[0], model1.H.shape[1]), trainable_W=False, rank = 400)\n",
    "model_new.cuda()\n",
    "V_new = V_new.cuda()\n",
    "model_new.fit(V_new)\n",
    "\n",
    "#return the gpu\n",
    "V_new = V_new.cpu()\n",
    "model_new = model_new.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_image = model_new.H @ model_new.W.t()\n",
    "reconstructed_image.shape\n",
    "reshaped_image = reconstructed_image.reshape(gray_image.shape[0], gray_image.shape[1])\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(reshaped_image.detach().numpy(), cmap = 'gray')\n",
    "ax[0].set_title('Reconstructed Image')\n",
    "ax[1].imshow(gray_image, cmap = 'gray')\n",
    "ax[1].set_title('Original Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what factors are used in this reconstruction?\n",
    "\n",
    "components = model_new.H.detach().cpu()\n",
    "indicies = list(range(len(components[0])))\n",
    "inx_components = list(zip(components[0], indicies))\n",
    "\n",
    "sorted_components = sorted(inx_components, key=lambda x: x[0])\n",
    "sorted_components.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 10\n",
    "idx = [sc[1] for sc in sorted_components[0:num_features]]\n",
    "\n",
    "features = model_new.W.t()\n",
    "image_components = features.reshape(features.shape[0], gray_image.shape[0], gray_image.shape[1])\n",
    "image_components = image_components.detach().cpu().numpy()\n",
    "\n",
    "top_features = image_components[idx]\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 7), subplot_kw={'xticks': (), 'yticks': ()})\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.imshow(top_features[i], cmap = 'gray')\n",
    "    ax.set_title(f'Feature {i+1}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = W1\n",
    "gray_components = model.H\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "num_components = gray_components.shape[0]\n",
    "useful_components = np.where(w>=0.5)[1]\n",
    "\n",
    "print(useful_components)\n",
    "\n",
    "fig, axes = plt.subplots(1,len(useful_components), figsize=(15, 7), subplot_kw={'xticks': (), 'yticks': ()})\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    component = useful_components[i]\n",
    "    ax.imshow(w[component].reshape(gray_image.shape[1], gray_image.shape[2]), cmap='gray')\n",
    "    ax.set_title(f'Feature {useful_components[i]+1}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchnmf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
